{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "annual-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bridal-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda GeForce MX130\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device, torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-corpus",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formed-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.zeros((1, 3, 800, 800)).float()\n",
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]])\n",
    "labels = torch.LongTensor([6, 8])\n",
    "sub_sample = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepted-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "fe = list(model.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-board",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abstract-spokesman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "## Passing the image through the CNN\n",
    "req_features = []\n",
    "model = model.to(device)\n",
    "k = image.clone().to(device)\n",
    "for i in fe:\n",
    "    k= i(k)\n",
    "    if k.size()[2] < 800//16:\n",
    "        break\n",
    "    req_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "print(len(req_features))\n",
    "print(out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "overall-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_fe_extractor = nn.Sequential(*req_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "competitive-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "image = torch.Tensor(image).to(device)\n",
    "out_map = faster_rcnn_fe_extractor(image)\n",
    "print(out_map.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-matrix",
   "metadata": {},
   "source": [
    "### Generating Anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "composite-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 anchors for each anchor point, y1, x1, y2, x2\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4), dtype=np.float32)\n",
    "print(\"9 anchors for each anchor point, y1, x1, y2, x2\")\n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dimensional-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 8.0\n",
      "[[ -37.254833  -82.50967    53.254833   98.50967 ]\n",
      " [ -82.50967  -173.01933    98.50967   189.01933 ]\n",
      " [-173.01933  -354.03867   189.01933   370.03867 ]\n",
      " [ -56.        -56.         72.         72.      ]\n",
      " [-120.       -120.        136.        136.      ]\n",
      " [-248.       -248.        264.        264.      ]\n",
      " [ -82.50967   -37.254833   98.50967    53.254833]\n",
      " [-173.01933   -82.50967   189.01933    98.50967 ]\n",
      " [-354.03867  -173.01933   370.03867   189.01933 ]]\n"
     ]
    }
   ],
   "source": [
    "## Filling the empty anchor base\n",
    "sub_sample = 16\n",
    "ctr_y = sub_sample / 2.\n",
    "ctr_x = sub_sample / 2.\n",
    "index = 0\n",
    "print(ctr_x,  ctr_y)\n",
    "for i in range(len(ratios)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "        h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])\n",
    "        w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratios[i])\n",
    "        index = i * len(anchor_scales) + j\n",
    "        anchor_base[index, 0] = ctr_y - h / 2.\n",
    "        anchor_base[index, 1] = ctr_x - w / 2.\n",
    "        anchor_base[index, 2] = ctr_y + h / 2.\n",
    "        anchor_base[index, 3] = ctr_x + w / 2.\n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-sally",
   "metadata": {},
   "source": [
    "### Generating the centres for each feature map pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "alien-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 [ 16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272 288\n",
      " 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560 576\n",
      " 592 608 624 640 656 672 688 704 720 736 752 768 784 800]\n"
     ]
    }
   ],
   "source": [
    "fe_size = 800 //16\n",
    "ctr_x = np.arange(16, (fe_size+1)*16, 16)\n",
    "ctr_y = np.arange(16, (fe_size+1)*16, 16)\n",
    "print(len(ctr_x), ctr_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "welcome-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 2)\n"
     ]
    }
   ],
   "source": [
    "## co-ordinates of the 2500 center points to generate anchors\n",
    "index = 0\n",
    "ctr = np.zeros((2500, 2))\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        ctr[index, 1] = ctr_x[x] - 8\n",
    "        ctr[index, 0] = ctr_y[y] - 8\n",
    "        index +=1\n",
    "print(ctr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "about-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 4)\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.5, 1, 2]\n",
    "scales = [8, 16, 32]\n",
    "sub_sample = 16\n",
    "anchor_boxes = np.zeros( ((fe_size * fe_size * 9), 4))\n",
    "index = 0\n",
    "for c in ctr:\n",
    "    ctr_y, ctr_x = c\n",
    "    for i in range(len(ratios)):\n",
    "        for j in range(len(scales)):\n",
    "            h = sub_sample * scales[j] * np.sqrt(ratios[i])\n",
    "            w = sub_sample * scales[j] * np.sqrt(1./ ratios[i])\n",
    "            anchor_boxes[index, 0] = ctr_y - h / 2.\n",
    "            anchor_boxes[index, 1] = ctr_x - w / 2.\n",
    "            anchor_boxes[index, 2] = ctr_y + h / 2.\n",
    "            anchor_boxes[index, 3] = ctr_x + w / 2.\n",
    "            index += 1\n",
    "print(anchor_boxes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-affiliation",
   "metadata": {},
   "source": [
    "### Assigning labels to anchor boxes\n",
    "After generating 22500 anchor boxes for every anchor point. Now we need to find the anchor boxes which have a higher IOU with the ground truth box.<br> \n",
    "##### Assigning label 1 (Intersecting ground truth box)<br>\n",
    "1. Has the highest IOU with ground truth box\n",
    "2. Has an IOU overlap after 0.7 with ground truth box\n",
    "\n",
    "##### Assigning (-1) (Not intersecting ground truth box)\n",
    "<br>\n",
    "1. negative label to a non-positive anchor if its IoU ratio is lower than 0.3 for all ground-truth boxes\n",
    "<BR><BR>\n",
    "Anchor boxes that are neither positive or negative are ignored for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "recreational-substance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "(8940, 4)\n"
     ]
    }
   ],
   "source": [
    "index_inside = np.where(\n",
    "        (anchor_boxes[:, 0] >= 0) &\n",
    "        (anchor_boxes[:, 1] >= 0) &\n",
    "        (anchor_boxes[:, 2] <= 800) &\n",
    "        (anchor_boxes[:, 3] <= 800)\n",
    "    )[0]\n",
    "print(index_inside.shape)\n",
    "\n",
    "valid_anchor_boxes = anchor_boxes[index_inside]\n",
    "print(valid_anchor_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fitted-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "label = np.empty((len(index_inside),), dtype = np.int32)\n",
    "label.fill(-1)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "defined-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 4)\n"
     ]
    }
   ],
   "source": [
    "valid_anchor_boxes = anchors[index_inside]\n",
    "print(valid_anchor_boxes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-nursing",
   "metadata": {},
   "source": [
    "###  Calculating IOU with each ground truth box\n",
    "- Find the max of x1 and y1 in both the boxes (xn1, yn1)\n",
    "- Find the min of x2 and y2 in both the boxes (xn2, yn2)\n",
    "- Now both the boxes are intersecting only\n",
    " if (xn1 < xn2) and (yn2 < yn1)\n",
    "      - iou_area will be (xn2 - xn1) * (yn2 - yn1)\n",
    " else\n",
    "      - iuo_area will be 0\n",
    "- similarly calculate area for anchor box and ground truth object\n",
    "- iou = iou_area/(anchor_box_area + ground_truth_area - iou_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "accompanied-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 20.,  30., 400., 500.],\n",
      "        [300., 400., 500., 600.]])\n",
      "(8940, 2)\n"
     ]
    }
   ],
   "source": [
    "ious = np.empty((len(valid_anchor_boxes), 2), dtype=np.float32)\n",
    "ious.fill(0)\n",
    "print(bbox)\n",
    "for num1, i in enumerate(valid_anchor_boxes):\n",
    "    ya1, xa1, ya2, xa2 = i  \n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
    "    for num2, j in enumerate(bbox):\n",
    "        yb1, xb1, yb2, xb2 = j\n",
    "        box_area = (yb2- yb1) * (xb2 - xb1)\n",
    "        inter_x1 = max([xb1, xa1])\n",
    "        inter_y1 = max([yb1, ya1])\n",
    "        inter_x2 = min([xb2, xa2])\n",
    "        inter_y2 = min([yb2, ya2])\n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * \\\n",
    "(inter_x2 - inter_x1)\n",
    "            iou = iter_area / \\\n",
    "(anchor_area+ box_area - iter_area)            \n",
    "        else:\n",
    "            iou = 0.\n",
    "        ious[num1, num2] = iou\n",
    "print(ious.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "blocked-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1561 6118]\n",
      "[0.73388577 0.8192    ]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = ious.argmax(axis=0)\n",
    "print(gt_argmax_ious)\n",
    "\n",
    "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n",
    "print(gt_max_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "national-memphis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.10643058 0.11084077 0.11084077 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "argmax_ious = ious.argmax(axis=1)\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious)\n",
    "max_ious = ious[np.arange(len(index_inside)), argmax_ious]\n",
    "print(max_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "logical-shanghai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1561 1789 2017 2245 2491 2737 2983 6118 6122 6126 6130]\n"
     ]
    }
   ],
   "source": [
    "# Find the anchor_boxes which have this max_ious (gt_max_ious)\n",
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
    "print(gt_argmax_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-startup",
   "metadata": {},
   "source": [
    "### The three arrays\n",
    "- argmax_ious — Tells which ground truth object has max iou with each anchor.\n",
    "- max_ious — Tells the max_iou with ground truth object with each anchor.\n",
    "- gt_argmax_ious — Tells the anchors with the highest Intersection-over-Union (IoU) overlap with a ground-truth box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "skilled-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Threshold variables\n",
    "pos_iou_threshold  = 0.7\n",
    "neg_iou_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-information",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
